{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c5043df3-8039-495b-8614-cd34d1eb9814",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import numpy as np\n",
    "\n",
    "# mne imports\n",
    "import mne\n",
    "from mne import io\n",
    "from mne.datasets import sample\n",
    "\n",
    "# EEGNet-specific imports\n",
    "from EEGModels import EEGNet\n",
    "from tensorflow.keras import utils as np_utils\n",
    "from tensorflow.keras.callbacks import ModelCheckpoint\n",
    "from tensorflow.keras import backend as K\n",
    "\n",
    "# PyRiemann imports\n",
    "from pyriemann.estimation import XdawnCovariances\n",
    "from pyriemann.tangentspace import TangentSpace\n",
    "from pyriemann.utils.viz import plot_confusion_matrix\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "# tools for plotting confusion matrices\n",
    "from matplotlib import pyplot as plt\n",
    "\n",
    "from dataloader import get_loader\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# while the default tensorflow ordering is 'channels_last' we set it here\n",
    "# to be explicit in case if the user has changed the default ordering\n",
    "K.set_image_data_format('channels_last')\n",
    "\n",
    "\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "scaler = StandardScaler()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "850ee2f3-cdd9-4641-9947-ff7e94422dde",
   "metadata": {},
   "outputs": [],
   "source": [
    "root = '/Volumes/Datasets/inner_speech/derivatives/'\n",
    "# root =  'dataset/derivatives/' # -sil\n",
    "creater = get_loader(root, n_sess= 3)\n",
    "\n",
    "# extract raw data. scale by 1000 due to scaling sensitivity in deep learning\n",
    "X, y = creater.load_multiple_subjects([1, 2, 4, 5, 6, 7]) # format is in (trials, channels, samples)\n",
    "y = y[:, 1]\n",
    "#X = X*1000\n",
    "\n",
    "\"\"\"\n",
    "import numpy as np\n",
    "from scipy.signal import butter, lfilter, freqz\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "\n",
    "def butter_lowpass(cutoff, fs, order=5):\n",
    "    nyq = 0.5 * fs\n",
    "    normal_cutoff = cutoff / nyq\n",
    "    b, a = butter(order, normal_cutoff, btype='low', analog=False)\n",
    "    return b, a\n",
    "\n",
    "def butter_lowpass_filter(data, cutoff, fs, order=5):\n",
    "    b, a = butter_lowpass(cutoff, fs, order=order)\n",
    "    y = lfilter(b, a, data)\n",
    "    return y\n",
    "\n",
    "\n",
    "# Setting standard filter requirements.\n",
    "order = 10\n",
    "fs = 1024       \n",
    "cutoff = 15  \n",
    "\n",
    "\n",
    "# Filtering and plotting\n",
    "X = butter_lowpass_filter(X, cutoff, fs, order)\n",
    "\n",
    "X = X*1000\n",
    "\"\"\"\n",
    "\n",
    "X_train, X_test, Y_train, Y_test = train_test_split(X, y, test_size=0.25, random_state=42)\n",
    "\n",
    "X_validate, X_test, Y_validate, Y_test = train_test_split(X_test, Y_test, test_size=0.50, random_state=42)\n",
    "\n",
    "\n",
    "scaler = StandardScaler()\n",
    "X_train = scaler.fit_transform(X_train.reshape(-1, X_train.shape[-1])).reshape(X_train.shape)\n",
    "X_test = scaler.transform(X_test.reshape(-1, X_test.shape[-1])).reshape(X_test.shape)\n",
    "X_validate = scaler.transform(X_validate.reshape(-1, X_validate.shape[-1])).reshape(X_validate.shape)\n",
    "\n",
    "\n",
    "kernels, chans, samples = 1, 128, 1153\n",
    "\n",
    "N, _, _ = X.shape\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8160a753-6701-41ac-8ce1-2fee6541f1cd",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "bf3719c4-e35f-421e-848b-5dbb23055042",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_train shape: (1032, 128, 1153, 1)\n",
      "1032 train samples\n",
      "172 test samples\n"
     ]
    }
   ],
   "source": [
    "# convert labels to one-hot encodings.\n",
    "Y_train      = np_utils.to_categorical(Y_train-1)\n",
    "Y_validate   = np_utils.to_categorical(Y_validate-1)\n",
    "Y_test       = np_utils.to_categorical(Y_test-1)\n",
    "\n",
    "# convert data to NHWC (trials, channels, samples, kernels) format. Data \n",
    "# contains 60 channels and 151 time-points. Set the number of kernels to 1.\n",
    "X_train      = X_train.reshape(X_train.shape[0], chans, samples, kernels)\n",
    "X_validate   = X_validate.reshape(X_validate.shape[0], chans, samples, kernels)\n",
    "X_test       = X_test.reshape(X_test.shape[0], chans, samples, kernels)\n",
    "   \n",
    "print('X_train shape:', X_train.shape)\n",
    "print(X_train.shape[0], 'train samples')\n",
    "print(X_test.shape[0], 'test samples')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d4c309d0-eb1e-45d4-9816-c0d760754385",
   "metadata": {},
   "outputs": [],
   "source": [
    "# configure the EEGNet-8,2,16 model with kernel length of 32 samples (other \n",
    "# model configurations may do better, but this is a good starting point)\n",
    "model = EEGNet(nb_classes = 4, Chans = chans, Samples = samples, \n",
    "               dropoutRate = 0.5, kernLength = 512, F1 = 8, D = 2, F2 = 16, \n",
    "               dropoutType = 'SpatialDropout2D')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "1462a973-8aff-4833-8b48-524c53a25312",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9124\n"
     ]
    }
   ],
   "source": [
    "import tensorflow_addons as tfa\n",
    "\n",
    "# define the loss function \n",
    "loss_function = tfa.losses.SigmoidFocalCrossEntropy()\n",
    "\n",
    "# compile the model and set the optimizers\n",
    "model.compile(loss='categorical_crossentropy', optimizer='adam', \n",
    "              metrics = ['accuracy'])\n",
    "\n",
    "# count number of parameters in the model\n",
    "numParams    = model.count_params()    \n",
    "\n",
    "# set a valid path for your system to record model checkpoints\n",
    "checkpointer = ModelCheckpoint(filepath='/tmp/checkpoint.h5', verbose=1,\n",
    "                               save_best_only=True)\n",
    "\n",
    "print(numParams)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2609fc23-a4cc-482a-8cb9-aedcb45712e5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/300\n",
      "65/65 - 399s - loss: 1.4217 - accuracy: 0.2558 - val_loss: 1.3925 - val_accuracy: 0.2035\n",
      "\n",
      "Epoch 00001: val_loss improved from inf to 1.39249, saving model to /tmp/checkpoint.h5\n",
      "Epoch 2/300\n",
      "65/65 - 397s - loss: 1.3874 - accuracy: 0.2829 - val_loss: 1.3955 - val_accuracy: 0.2326\n",
      "\n",
      "Epoch 00002: val_loss did not improve from 1.39249\n",
      "Epoch 3/300\n",
      "65/65 - 396s - loss: 1.3667 - accuracy: 0.2975 - val_loss: 1.3951 - val_accuracy: 0.2616\n",
      "\n",
      "Epoch 00003: val_loss did not improve from 1.39249\n",
      "Epoch 4/300\n",
      "65/65 - 396s - loss: 1.3759 - accuracy: 0.3178 - val_loss: 1.3994 - val_accuracy: 0.2500\n",
      "\n",
      "Epoch 00004: val_loss did not improve from 1.39249\n",
      "Epoch 5/300\n",
      "65/65 - 395s - loss: 1.3369 - accuracy: 0.3576 - val_loss: 1.4038 - val_accuracy: 0.2733\n",
      "\n",
      "Epoch 00005: val_loss did not improve from 1.39249\n",
      "Epoch 6/300\n",
      "65/65 - 397s - loss: 1.3442 - accuracy: 0.3508 - val_loss: 1.3947 - val_accuracy: 0.2442\n",
      "\n",
      "Epoch 00006: val_loss did not improve from 1.39249\n",
      "Epoch 7/300\n",
      "65/65 - 394s - loss: 1.3368 - accuracy: 0.3634 - val_loss: 1.3833 - val_accuracy: 0.2674\n",
      "\n",
      "Epoch 00007: val_loss improved from 1.39249 to 1.38329, saving model to /tmp/checkpoint.h5\n",
      "Epoch 8/300\n",
      "65/65 - 396s - loss: 1.3202 - accuracy: 0.3808 - val_loss: 1.3843 - val_accuracy: 0.2616\n",
      "\n",
      "Epoch 00008: val_loss did not improve from 1.38329\n",
      "Epoch 9/300\n",
      "65/65 - 397s - loss: 1.3075 - accuracy: 0.3905 - val_loss: 1.4166 - val_accuracy: 0.2616\n",
      "\n",
      "Epoch 00009: val_loss did not improve from 1.38329\n",
      "Epoch 10/300\n",
      "65/65 - 424s - loss: 1.3124 - accuracy: 0.3760 - val_loss: 1.4023 - val_accuracy: 0.2791\n",
      "\n",
      "Epoch 00010: val_loss did not improve from 1.38329\n",
      "Epoch 11/300\n",
      "65/65 - 445s - loss: 1.2823 - accuracy: 0.4167 - val_loss: 1.4402 - val_accuracy: 0.2267\n",
      "\n",
      "Epoch 00011: val_loss did not improve from 1.38329\n",
      "Epoch 12/300\n",
      "65/65 - 445s - loss: 1.2982 - accuracy: 0.3973 - val_loss: 1.4165 - val_accuracy: 0.2326\n",
      "\n",
      "Epoch 00012: val_loss did not improve from 1.38329\n",
      "Epoch 13/300\n",
      "65/65 - 445s - loss: 1.2847 - accuracy: 0.4109 - val_loss: 1.4003 - val_accuracy: 0.2616\n",
      "\n",
      "Epoch 00013: val_loss did not improve from 1.38329\n",
      "Epoch 14/300\n",
      "65/65 - 447s - loss: 1.2713 - accuracy: 0.4409 - val_loss: 1.4056 - val_accuracy: 0.2384\n",
      "\n",
      "Epoch 00014: val_loss did not improve from 1.38329\n",
      "Epoch 15/300\n",
      "65/65 - 447s - loss: 1.2777 - accuracy: 0.4050 - val_loss: 1.3925 - val_accuracy: 0.2500\n",
      "\n",
      "Epoch 00015: val_loss did not improve from 1.38329\n",
      "Epoch 16/300\n",
      "65/65 - 446s - loss: 1.2673 - accuracy: 0.4167 - val_loss: 1.4054 - val_accuracy: 0.2674\n",
      "\n",
      "Epoch 00016: val_loss did not improve from 1.38329\n",
      "Epoch 17/300\n",
      "65/65 - 445s - loss: 1.2628 - accuracy: 0.4399 - val_loss: 1.3920 - val_accuracy: 0.2616\n",
      "\n",
      "Epoch 00017: val_loss did not improve from 1.38329\n",
      "Epoch 18/300\n",
      "65/65 - 445s - loss: 1.2575 - accuracy: 0.4603 - val_loss: 1.4066 - val_accuracy: 0.2616\n",
      "\n",
      "Epoch 00018: val_loss did not improve from 1.38329\n",
      "Epoch 19/300\n",
      "65/65 - 446s - loss: 1.2491 - accuracy: 0.4399 - val_loss: 1.4057 - val_accuracy: 0.2791\n",
      "\n",
      "Epoch 00019: val_loss did not improve from 1.38329\n",
      "Epoch 20/300\n",
      "65/65 - 447s - loss: 1.2529 - accuracy: 0.4283 - val_loss: 1.4097 - val_accuracy: 0.2674\n",
      "\n",
      "Epoch 00020: val_loss did not improve from 1.38329\n",
      "Epoch 21/300\n",
      "65/65 - 448s - loss: 1.2291 - accuracy: 0.4477 - val_loss: 1.4175 - val_accuracy: 0.2733\n",
      "\n",
      "Epoch 00021: val_loss did not improve from 1.38329\n",
      "Epoch 22/300\n",
      "65/65 - 447s - loss: 1.2565 - accuracy: 0.4545 - val_loss: 1.4005 - val_accuracy: 0.3023\n",
      "\n",
      "Epoch 00022: val_loss did not improve from 1.38329\n",
      "Epoch 23/300\n",
      "65/65 - 448s - loss: 1.2127 - accuracy: 0.4777 - val_loss: 1.4152 - val_accuracy: 0.3023\n",
      "\n",
      "Epoch 00023: val_loss did not improve from 1.38329\n",
      "Epoch 24/300\n",
      "65/65 - 447s - loss: 1.2175 - accuracy: 0.4671 - val_loss: 1.4046 - val_accuracy: 0.2558\n",
      "\n",
      "Epoch 00024: val_loss did not improve from 1.38329\n",
      "Epoch 25/300\n",
      "65/65 - 446s - loss: 1.2208 - accuracy: 0.4738 - val_loss: 1.4112 - val_accuracy: 0.3140\n",
      "\n",
      "Epoch 00025: val_loss did not improve from 1.38329\n",
      "Epoch 26/300\n",
      "65/65 - 447s - loss: 1.2270 - accuracy: 0.4748 - val_loss: 1.3925 - val_accuracy: 0.2965\n",
      "\n",
      "Epoch 00026: val_loss did not improve from 1.38329\n",
      "Epoch 27/300\n",
      "65/65 - 445s - loss: 1.1975 - accuracy: 0.4826 - val_loss: 1.4045 - val_accuracy: 0.2907\n",
      "\n",
      "Epoch 00027: val_loss did not improve from 1.38329\n",
      "Epoch 28/300\n",
      "65/65 - 446s - loss: 1.1981 - accuracy: 0.4729 - val_loss: 1.4379 - val_accuracy: 0.2733\n",
      "\n",
      "Epoch 00028: val_loss did not improve from 1.38329\n",
      "Epoch 29/300\n",
      "65/65 - 445s - loss: 1.2053 - accuracy: 0.4826 - val_loss: 1.3890 - val_accuracy: 0.2907\n",
      "\n",
      "Epoch 00029: val_loss did not improve from 1.38329\n",
      "Epoch 30/300\n",
      "65/65 - 448s - loss: 1.1852 - accuracy: 0.4932 - val_loss: 1.3987 - val_accuracy: 0.3605\n",
      "\n",
      "Epoch 00030: val_loss did not improve from 1.38329\n",
      "Epoch 31/300\n",
      "65/65 - 446s - loss: 1.1721 - accuracy: 0.4971 - val_loss: 1.4115 - val_accuracy: 0.2965\n",
      "\n",
      "Epoch 00031: val_loss did not improve from 1.38329\n",
      "Epoch 32/300\n",
      "65/65 - 449s - loss: 1.1773 - accuracy: 0.4864 - val_loss: 1.4236 - val_accuracy: 0.2965\n",
      "\n",
      "Epoch 00032: val_loss did not improve from 1.38329\n",
      "Epoch 33/300\n",
      "65/65 - 448s - loss: 1.1521 - accuracy: 0.5019 - val_loss: 1.4141 - val_accuracy: 0.3081\n",
      "\n",
      "Epoch 00033: val_loss did not improve from 1.38329\n",
      "Epoch 34/300\n",
      "65/65 - 446s - loss: 1.1830 - accuracy: 0.4767 - val_loss: 1.4099 - val_accuracy: 0.2791\n",
      "\n",
      "Epoch 00034: val_loss did not improve from 1.38329\n",
      "Epoch 35/300\n",
      "65/65 - 449s - loss: 1.1713 - accuracy: 0.4903 - val_loss: 1.4079 - val_accuracy: 0.2965\n",
      "\n",
      "Epoch 00035: val_loss did not improve from 1.38329\n",
      "Epoch 36/300\n",
      "65/65 - 448s - loss: 1.1607 - accuracy: 0.4971 - val_loss: 1.4299 - val_accuracy: 0.3023\n",
      "\n",
      "Epoch 00036: val_loss did not improve from 1.38329\n",
      "Epoch 37/300\n",
      "65/65 - 449s - loss: 1.1607 - accuracy: 0.4884 - val_loss: 1.4536 - val_accuracy: 0.2907\n",
      "\n",
      "Epoch 00037: val_loss did not improve from 1.38329\n",
      "Epoch 38/300\n",
      "65/65 - 451s - loss: 1.1738 - accuracy: 0.4748 - val_loss: 1.4339 - val_accuracy: 0.3198\n",
      "\n",
      "Epoch 00038: val_loss did not improve from 1.38329\n",
      "Epoch 39/300\n",
      "65/65 - 448s - loss: 1.1397 - accuracy: 0.5039 - val_loss: 1.4451 - val_accuracy: 0.3023\n",
      "\n",
      "Epoch 00039: val_loss did not improve from 1.38329\n",
      "Epoch 40/300\n",
      "65/65 - 449s - loss: 1.1383 - accuracy: 0.5019 - val_loss: 1.4237 - val_accuracy: 0.2965\n",
      "\n",
      "Epoch 00040: val_loss did not improve from 1.38329\n",
      "Epoch 41/300\n",
      "65/65 - 448s - loss: 1.1560 - accuracy: 0.5097 - val_loss: 1.4219 - val_accuracy: 0.2733\n",
      "\n",
      "Epoch 00041: val_loss did not improve from 1.38329\n",
      "Epoch 42/300\n",
      "65/65 - 451s - loss: 1.1226 - accuracy: 0.5233 - val_loss: 1.4332 - val_accuracy: 0.2965\n",
      "\n",
      "Epoch 00042: val_loss did not improve from 1.38329\n",
      "Epoch 43/300\n",
      "65/65 - 447s - loss: 1.1268 - accuracy: 0.5029 - val_loss: 1.4421 - val_accuracy: 0.3023\n",
      "\n",
      "Epoch 00043: val_loss did not improve from 1.38329\n",
      "Epoch 44/300\n",
      "65/65 - 447s - loss: 1.1409 - accuracy: 0.5058 - val_loss: 1.4328 - val_accuracy: 0.2965\n",
      "\n",
      "Epoch 00044: val_loss did not improve from 1.38329\n",
      "Epoch 45/300\n",
      "65/65 - 445s - loss: 1.1147 - accuracy: 0.5300 - val_loss: 1.4301 - val_accuracy: 0.3372\n",
      "\n",
      "Epoch 00045: val_loss did not improve from 1.38329\n",
      "Epoch 46/300\n",
      "65/65 - 445s - loss: 1.1708 - accuracy: 0.4797 - val_loss: 1.4097 - val_accuracy: 0.3314\n",
      "\n",
      "Epoch 00046: val_loss did not improve from 1.38329\n",
      "Epoch 47/300\n",
      "65/65 - 451s - loss: 1.1240 - accuracy: 0.5436 - val_loss: 1.4431 - val_accuracy: 0.2965\n",
      "\n",
      "Epoch 00047: val_loss did not improve from 1.38329\n",
      "Epoch 48/300\n",
      "65/65 - 448s - loss: 1.1317 - accuracy: 0.5223 - val_loss: 1.4332 - val_accuracy: 0.2791\n",
      "\n",
      "Epoch 00048: val_loss did not improve from 1.38329\n",
      "Epoch 49/300\n",
      "65/65 - 448s - loss: 1.1166 - accuracy: 0.5359 - val_loss: 1.4447 - val_accuracy: 0.3140\n",
      "\n",
      "Epoch 00049: val_loss did not improve from 1.38329\n",
      "Epoch 50/300\n",
      "65/65 - 453s - loss: 1.1161 - accuracy: 0.5339 - val_loss: 1.4328 - val_accuracy: 0.2616\n",
      "\n",
      "Epoch 00050: val_loss did not improve from 1.38329\n",
      "Epoch 51/300\n",
      "65/65 - 449s - loss: 1.1365 - accuracy: 0.5058 - val_loss: 1.4377 - val_accuracy: 0.2907\n",
      "\n",
      "Epoch 00051: val_loss did not improve from 1.38329\n",
      "Epoch 52/300\n",
      "65/65 - 451s - loss: 1.1116 - accuracy: 0.5291 - val_loss: 1.4316 - val_accuracy: 0.3140\n",
      "\n",
      "Epoch 00052: val_loss did not improve from 1.38329\n",
      "Epoch 53/300\n",
      "65/65 - 448s - loss: 1.0987 - accuracy: 0.5562 - val_loss: 1.4197 - val_accuracy: 0.3372\n",
      "\n",
      "Epoch 00053: val_loss did not improve from 1.38329\n",
      "Epoch 54/300\n",
      "65/65 - 450s - loss: 1.1167 - accuracy: 0.5484 - val_loss: 1.4413 - val_accuracy: 0.2965\n",
      "\n",
      "Epoch 00054: val_loss did not improve from 1.38329\n",
      "Epoch 55/300\n",
      "65/65 - 449s - loss: 1.1175 - accuracy: 0.5291 - val_loss: 1.4776 - val_accuracy: 0.2616\n",
      "\n",
      "Epoch 00055: val_loss did not improve from 1.38329\n",
      "Epoch 56/300\n",
      "65/65 - 449s - loss: 1.0899 - accuracy: 0.5417 - val_loss: 1.4583 - val_accuracy: 0.2791\n",
      "\n",
      "Epoch 00056: val_loss did not improve from 1.38329\n",
      "Epoch 57/300\n",
      "65/65 - 453s - loss: 1.0821 - accuracy: 0.5475 - val_loss: 1.4621 - val_accuracy: 0.2733\n",
      "\n",
      "Epoch 00057: val_loss did not improve from 1.38329\n",
      "Epoch 58/300\n",
      "65/65 - 447s - loss: 1.0833 - accuracy: 0.5504 - val_loss: 1.4470 - val_accuracy: 0.3547\n",
      "\n",
      "Epoch 00058: val_loss did not improve from 1.38329\n",
      "Epoch 59/300\n",
      "65/65 - 447s - loss: 1.0941 - accuracy: 0.5349 - val_loss: 1.4577 - val_accuracy: 0.2674\n",
      "\n",
      "Epoch 00059: val_loss did not improve from 1.38329\n",
      "Epoch 60/300\n",
      "65/65 - 448s - loss: 1.0885 - accuracy: 0.5475 - val_loss: 1.4539 - val_accuracy: 0.2907\n",
      "\n",
      "Epoch 00060: val_loss did not improve from 1.38329\n",
      "Epoch 61/300\n",
      "65/65 - 448s - loss: 1.1070 - accuracy: 0.5078 - val_loss: 1.4680 - val_accuracy: 0.3023\n",
      "\n",
      "Epoch 00061: val_loss did not improve from 1.38329\n",
      "Epoch 62/300\n",
      "65/65 - 454s - loss: 1.1105 - accuracy: 0.5426 - val_loss: 1.4210 - val_accuracy: 0.2849\n",
      "\n",
      "Epoch 00062: val_loss did not improve from 1.38329\n",
      "Epoch 63/300\n",
      "65/65 - 450s - loss: 1.0910 - accuracy: 0.5504 - val_loss: 1.4605 - val_accuracy: 0.2965\n",
      "\n",
      "Epoch 00063: val_loss did not improve from 1.38329\n",
      "Epoch 64/300\n",
      "65/65 - 453s - loss: 1.0578 - accuracy: 0.5581 - val_loss: 1.5020 - val_accuracy: 0.3023\n",
      "\n",
      "Epoch 00064: val_loss did not improve from 1.38329\n",
      "Epoch 65/300\n",
      "65/65 - 450s - loss: 1.0851 - accuracy: 0.5455 - val_loss: 1.4842 - val_accuracy: 0.2907\n",
      "\n",
      "Epoch 00065: val_loss did not improve from 1.38329\n",
      "Epoch 66/300\n",
      "65/65 - 448s - loss: 1.0661 - accuracy: 0.5620 - val_loss: 1.4403 - val_accuracy: 0.3081\n",
      "\n",
      "Epoch 00066: val_loss did not improve from 1.38329\n",
      "Epoch 67/300\n",
      "65/65 - 451s - loss: 1.0940 - accuracy: 0.5446 - val_loss: 1.4613 - val_accuracy: 0.3140\n",
      "\n",
      "Epoch 00067: val_loss did not improve from 1.38329\n",
      "Epoch 68/300\n",
      "65/65 - 448s - loss: 1.0725 - accuracy: 0.5543 - val_loss: 1.4709 - val_accuracy: 0.2849\n",
      "\n",
      "Epoch 00068: val_loss did not improve from 1.38329\n",
      "Epoch 69/300\n",
      "65/65 - 447s - loss: 1.0768 - accuracy: 0.5446 - val_loss: 1.4776 - val_accuracy: 0.2907\n",
      "\n",
      "Epoch 00069: val_loss did not improve from 1.38329\n",
      "Epoch 70/300\n",
      "65/65 - 452s - loss: 1.0767 - accuracy: 0.5552 - val_loss: 1.4569 - val_accuracy: 0.3140\n",
      "\n",
      "Epoch 00070: val_loss did not improve from 1.38329\n",
      "Epoch 71/300\n",
      "65/65 - 446s - loss: 1.0676 - accuracy: 0.5465 - val_loss: 1.4921 - val_accuracy: 0.2791\n",
      "\n",
      "Epoch 00071: val_loss did not improve from 1.38329\n",
      "Epoch 72/300\n",
      "65/65 - 447s - loss: 1.0256 - accuracy: 0.5853 - val_loss: 1.4834 - val_accuracy: 0.2674\n",
      "\n",
      "Epoch 00072: val_loss did not improve from 1.38329\n",
      "Epoch 73/300\n",
      "65/65 - 449s - loss: 1.0657 - accuracy: 0.5465 - val_loss: 1.5098 - val_accuracy: 0.3140\n",
      "\n",
      "Epoch 00073: val_loss did not improve from 1.38329\n",
      "Epoch 74/300\n",
      "65/65 - 452s - loss: 1.1053 - accuracy: 0.5339 - val_loss: 1.4737 - val_accuracy: 0.3140\n",
      "\n",
      "Epoch 00074: val_loss did not improve from 1.38329\n",
      "Epoch 75/300\n",
      "65/65 - 446s - loss: 1.0552 - accuracy: 0.5591 - val_loss: 1.4918 - val_accuracy: 0.3023\n",
      "\n",
      "Epoch 00075: val_loss did not improve from 1.38329\n",
      "Epoch 76/300\n",
      "65/65 - 450s - loss: 1.0862 - accuracy: 0.5426 - val_loss: 1.4866 - val_accuracy: 0.3140\n",
      "\n",
      "Epoch 00076: val_loss did not improve from 1.38329\n",
      "Epoch 77/300\n",
      "65/65 - 454s - loss: 1.0596 - accuracy: 0.5630 - val_loss: 1.4952 - val_accuracy: 0.3140\n",
      "\n",
      "Epoch 00077: val_loss did not improve from 1.38329\n",
      "Epoch 78/300\n",
      "65/65 - 450s - loss: 1.0459 - accuracy: 0.5669 - val_loss: 1.4917 - val_accuracy: 0.3372\n",
      "\n",
      "Epoch 00078: val_loss did not improve from 1.38329\n",
      "Epoch 79/300\n",
      "65/65 - 447s - loss: 1.0633 - accuracy: 0.5388 - val_loss: 1.4683 - val_accuracy: 0.2384\n",
      "\n",
      "Epoch 00079: val_loss did not improve from 1.38329\n",
      "Epoch 80/300\n",
      "65/65 - 448s - loss: 1.0693 - accuracy: 0.5436 - val_loss: 1.4865 - val_accuracy: 0.3023\n",
      "\n",
      "Epoch 00080: val_loss did not improve from 1.38329\n",
      "Epoch 81/300\n",
      "65/65 - 421s - loss: 1.0408 - accuracy: 0.5814 - val_loss: 1.4863 - val_accuracy: 0.3140\n",
      "\n",
      "Epoch 00081: val_loss did not improve from 1.38329\n",
      "Epoch 82/300\n",
      "65/65 - 429s - loss: 1.0501 - accuracy: 0.5523 - val_loss: 1.4686 - val_accuracy: 0.3023\n",
      "\n",
      "Epoch 00082: val_loss did not improve from 1.38329\n",
      "Epoch 83/300\n",
      "65/65 - 444s - loss: 1.0622 - accuracy: 0.5678 - val_loss: 1.4684 - val_accuracy: 0.2965\n",
      "\n",
      "Epoch 00083: val_loss did not improve from 1.38329\n",
      "Epoch 84/300\n"
     ]
    }
   ],
   "source": [
    "###############################################################################\n",
    "# if the classification task was imbalanced (significantly more trials in one\n",
    "# class versus the others) you can assign a weight to each class during \n",
    "# optimization to balance it out. This data is approximately balanced so we \n",
    "# don't need to do this, but is shown here for illustration/completeness. \n",
    "###############################################################################\n",
    "\n",
    "# the syntax is {class_1:weight_1, class_2:weight_2,...}. Here just setting\n",
    "# the weights all to be 1\n",
    "class_weights = {0:1, 1:1, 2:1, 3:1}\n",
    "\n",
    "################################################################################\n",
    "# fit the model. Due to very small sample sizes this can get\n",
    "# pretty noisy run-to-run, but most runs should be comparable to xDAWN + \n",
    "# Riemannian geometry classification (below)\n",
    "################################################################################\n",
    "fittedModel = model.fit(X_train, Y_train, batch_size = 16, epochs = 300, \n",
    "                        verbose = 2, validation_data=(X_validate, Y_validate),\n",
    "                        callbacks=[checkpointer])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a262fd58-fee7-4d1b-927b-85cf93492e49",
   "metadata": {},
   "outputs": [],
   "source": [
    "###############################################################################\n",
    "# make prediction on test set.\n",
    "###############################################################################\n",
    "\n",
    "probs       = model.predict(X_test)\n",
    "preds       = probs.argmax(axis = -1)  \n",
    "acc         = np.mean(preds == Y_test.argmax(axis=-1))\n",
    "print(\"Classification accuracy: %f \" % (acc))\n",
    "\n",
    "from sklearn.metrics import confusion_matrix, ConfusionMatrixDisplay\n",
    "cm = confusion_matrix(Y_test.argmax(axis=-1), preds)\n",
    "disp = ConfusionMatrixDisplay(confusion_matrix=cm)\n",
    "disp.plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e1bcd182-c2c1-4f9a-bbea-776b46be26dd",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "31f6a130-6c43-4d97-81aa-ac3852342dfd",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ca8584b-e554-4eb6-bb6e-40b84e194f1d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef21c5a2-2c10-4126-b33d-845de15c4280",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a7d42f3e-c04e-44e2-8f3f-b0b5c33f0625",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a126170e-8b7e-44bf-8370-031e4322f1de",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "91349487-e0fa-4247-b199-34f8f6f78238",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a0a78bb-35e2-444c-954d-08c622217f8f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
