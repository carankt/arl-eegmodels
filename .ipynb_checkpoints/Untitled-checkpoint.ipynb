{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c5043df3-8039-495b-8614-cd34d1eb9814",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import numpy as np\n",
    "\n",
    "# mne imports\n",
    "import mne\n",
    "from mne import io\n",
    "from mne.datasets import sample\n",
    "\n",
    "# EEGNet-specific imports\n",
    "from EEGModels import EEGNet\n",
    "from tensorflow.keras import utils as np_utils\n",
    "from tensorflow.keras.callbacks import ModelCheckpoint\n",
    "from tensorflow.keras import backend as K\n",
    "\n",
    "# PyRiemann imports\n",
    "from pyriemann.estimation import XdawnCovariances\n",
    "from pyriemann.tangentspace import TangentSpace\n",
    "from pyriemann.utils.viz import plot_confusion_matrix\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "# tools for plotting confusion matrices\n",
    "from matplotlib import pyplot as plt\n",
    "\n",
    "from dataloader import get_loader\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# while the default tensorflow ordering is 'channels_last' we set it here\n",
    "# to be explicit in case if the user has changed the default ordering\n",
    "K.set_image_data_format('channels_last')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "850ee2f3-cdd9-4641-9947-ff7e94422dde",
   "metadata": {},
   "outputs": [],
   "source": [
    "root = '/Volumes/Datasets/inner_speech/derivatives/'\n",
    "# root =  'dataset/derivatives/' # -sil\n",
    "creater = get_loader(root, channel_list= [\"A4\", \"A5\", \"A19\", \"A20\", \"A32\"], n_sess= 3)\n",
    "\n",
    "# extract raw data. scale by 1000 due to scaling sensitivity in deep learning\n",
    "X, y = creater.load_multiple_subjects([1, 2, 3, 4, 5, 6, 7, 8]) # format is in (trials, channels, samples)\n",
    "y = y[:, 1]\n",
    "#X = X*1000\n",
    "\n",
    "\n",
    "import numpy as np\n",
    "from scipy.signal import butter, lfilter, freqz\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "\n",
    "def butter_lowpass(cutoff, fs, order=5):\n",
    "    nyq = 0.5 * fs\n",
    "    normal_cutoff = cutoff / nyq\n",
    "    b, a = butter(order, normal_cutoff, btype='low', analog=False)\n",
    "    return b, a\n",
    "\n",
    "def butter_lowpass_filter(data, cutoff, fs, order=5):\n",
    "    b, a = butter_lowpass(cutoff, fs, order=order)\n",
    "    y = lfilter(b, a, data)\n",
    "    return y\n",
    "\n",
    "\n",
    "# Setting standard filter requirements.\n",
    "order = 10\n",
    "fs = 1024       \n",
    "cutoff = 15  \n",
    "\n",
    "\n",
    "# Filtering and plotting\n",
    "X = butter_lowpass_filter(X, cutoff, fs, order)\n",
    "\n",
    "X = X*1000\n",
    "\n",
    "X_train, X_test, Y_train, Y_test = train_test_split(X, y, test_size=0.25, random_state=42)\n",
    "\n",
    "X_validate, X_test, Y_validate, Y_test = train_test_split(X_test, Y_test, test_size=0.50, random_state=42)\n",
    "\n",
    "kernels, chans, samples = 1, 5, 1153\n",
    "\n",
    "N, _, _ = X.shape\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "bf3719c4-e35f-421e-848b-5dbb23055042",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_train shape: (1317, 5, 1153, 1)\n",
      "1317 train samples\n",
      "220 test samples\n"
     ]
    }
   ],
   "source": [
    "# convert labels to one-hot encodings.\n",
    "Y_train      = np_utils.to_categorical(Y_train-1)\n",
    "Y_validate   = np_utils.to_categorical(Y_validate-1)\n",
    "Y_test       = np_utils.to_categorical(Y_test-1)\n",
    "\n",
    "# convert data to NHWC (trials, channels, samples, kernels) format. Data \n",
    "# contains 60 channels and 151 time-points. Set the number of kernels to 1.\n",
    "X_train      = X_train.reshape(X_train.shape[0], chans, samples, kernels)\n",
    "X_validate   = X_validate.reshape(X_validate.shape[0], chans, samples, kernels)\n",
    "X_test       = X_test.reshape(X_test.shape[0], chans, samples, kernels)\n",
    "   \n",
    "print('X_train shape:', X_train.shape)\n",
    "print(X_train.shape[0], 'train samples')\n",
    "print(X_test.shape[0], 'test samples')\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "32451c2e-4eea-4726-b237-c5933eb73a9e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "d4c309d0-eb1e-45d4-9816-c0d760754385",
   "metadata": {},
   "outputs": [],
   "source": [
    "# configure the EEGNet-8,2,16 model with kernel length of 32 samples (other \n",
    "# model configurations may do better, but this is a good starting point)\n",
    "model = EEGNet(nb_classes = 4, Chans = chans, Samples = samples, \n",
    "               dropoutRate = 0.5, kernLength = 512, F1 = 32, D = 4, F2 = 128, \n",
    "               dropoutType = 'Dropout')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "1462a973-8aff-4833-8b48-524c53a25312",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "55044\n"
     ]
    }
   ],
   "source": [
    "import tensorflow_addons as tfa\n",
    "\n",
    "# define the loss function \n",
    "loss_function = tfa.losses.SigmoidFocalCrossEntropy()\n",
    "\n",
    "# compile the model and set the optimizers\n",
    "model.compile(loss=loss_function, optimizer='adam', \n",
    "              metrics = ['accuracy'])\n",
    "\n",
    "# count number of parameters in the model\n",
    "numParams    = model.count_params()    \n",
    "\n",
    "# set a valid path for your system to record model checkpoints\n",
    "checkpointer = ModelCheckpoint(filepath='/tmp/checkpoint.h5', verbose=1,\n",
    "                               save_best_only=True)\n",
    "\n",
    "print(numParams)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b0a274e7-32eb-4001-9884-8149e0732311",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "2609fc23-a4cc-482a-8cb9-aedcb45712e5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/300\n",
      "83/83 - 16s - loss: 0.5959 - accuracy: 0.2923 - val_loss: 0.5994 - val_accuracy: 0.3242\n",
      "\n",
      "Epoch 00001: val_loss improved from inf to 0.59935, saving model to /tmp/checkpoint.h5\n",
      "Epoch 2/300\n",
      "83/83 - 15s - loss: 0.5915 - accuracy: 0.3212 - val_loss: 0.5993 - val_accuracy: 0.2694\n",
      "\n",
      "Epoch 00002: val_loss improved from 0.59935 to 0.59928, saving model to /tmp/checkpoint.h5\n",
      "Epoch 3/300\n",
      "83/83 - 15s - loss: 0.5917 - accuracy: 0.3212 - val_loss: 0.6111 - val_accuracy: 0.2466\n",
      "\n",
      "Epoch 00003: val_loss did not improve from 0.59928\n",
      "Epoch 4/300\n",
      "83/83 - 15s - loss: 0.5918 - accuracy: 0.3068 - val_loss: 0.6020 - val_accuracy: 0.2740\n",
      "\n",
      "Epoch 00004: val_loss did not improve from 0.59928\n",
      "Epoch 5/300\n",
      "83/83 - 15s - loss: 0.5899 - accuracy: 0.3242 - val_loss: 0.6087 - val_accuracy: 0.2329\n",
      "\n",
      "Epoch 00005: val_loss did not improve from 0.59928\n",
      "Epoch 6/300\n",
      "83/83 - 15s - loss: 0.5892 - accuracy: 0.3311 - val_loss: 0.6026 - val_accuracy: 0.2557\n",
      "\n",
      "Epoch 00006: val_loss did not improve from 0.59928\n",
      "Epoch 7/300\n",
      "83/83 - 15s - loss: 0.5917 - accuracy: 0.3341 - val_loss: 0.6047 - val_accuracy: 0.2648\n",
      "\n",
      "Epoch 00007: val_loss did not improve from 0.59928\n",
      "Epoch 8/300\n",
      "83/83 - 15s - loss: 0.5897 - accuracy: 0.3242 - val_loss: 0.6097 - val_accuracy: 0.2694\n",
      "\n",
      "Epoch 00008: val_loss did not improve from 0.59928\n",
      "Epoch 9/300\n",
      "83/83 - 15s - loss: 0.5884 - accuracy: 0.3478 - val_loss: 0.6064 - val_accuracy: 0.2785\n",
      "\n",
      "Epoch 00009: val_loss did not improve from 0.59928\n",
      "Epoch 10/300\n",
      "83/83 - 15s - loss: 0.5876 - accuracy: 0.3402 - val_loss: 0.6106 - val_accuracy: 0.2100\n",
      "\n",
      "Epoch 00010: val_loss did not improve from 0.59928\n",
      "Epoch 11/300\n",
      "83/83 - 15s - loss: 0.5876 - accuracy: 0.3402 - val_loss: 0.6166 - val_accuracy: 0.2055\n",
      "\n",
      "Epoch 00011: val_loss did not improve from 0.59928\n",
      "Epoch 12/300\n",
      "83/83 - 15s - loss: 0.5858 - accuracy: 0.3364 - val_loss: 0.6158 - val_accuracy: 0.2100\n",
      "\n",
      "Epoch 00012: val_loss did not improve from 0.59928\n",
      "Epoch 13/300\n",
      "83/83 - 15s - loss: 0.5863 - accuracy: 0.3409 - val_loss: 0.6103 - val_accuracy: 0.2511\n",
      "\n",
      "Epoch 00013: val_loss did not improve from 0.59928\n",
      "Epoch 14/300\n",
      "83/83 - 15s - loss: 0.5870 - accuracy: 0.3402 - val_loss: 0.6107 - val_accuracy: 0.2329\n",
      "\n",
      "Epoch 00014: val_loss did not improve from 0.59928\n",
      "Epoch 15/300\n",
      "83/83 - 15s - loss: 0.5870 - accuracy: 0.3235 - val_loss: 0.6101 - val_accuracy: 0.2740\n",
      "\n",
      "Epoch 00015: val_loss did not improve from 0.59928\n",
      "Epoch 16/300\n",
      "83/83 - 15s - loss: 0.5861 - accuracy: 0.3394 - val_loss: 0.6086 - val_accuracy: 0.2785\n",
      "\n",
      "Epoch 00016: val_loss did not improve from 0.59928\n",
      "Epoch 17/300\n",
      "83/83 - 15s - loss: 0.5849 - accuracy: 0.3364 - val_loss: 0.6072 - val_accuracy: 0.2603\n",
      "\n",
      "Epoch 00017: val_loss did not improve from 0.59928\n",
      "Epoch 18/300\n",
      "83/83 - 15s - loss: 0.5878 - accuracy: 0.3379 - val_loss: 0.6121 - val_accuracy: 0.2557\n",
      "\n",
      "Epoch 00018: val_loss did not improve from 0.59928\n",
      "Epoch 19/300\n",
      "83/83 - 15s - loss: 0.5846 - accuracy: 0.3379 - val_loss: 0.6152 - val_accuracy: 0.2466\n",
      "\n",
      "Epoch 00019: val_loss did not improve from 0.59928\n",
      "Epoch 20/300\n",
      "83/83 - 15s - loss: 0.5823 - accuracy: 0.3516 - val_loss: 0.6072 - val_accuracy: 0.2694\n",
      "\n",
      "Epoch 00020: val_loss did not improve from 0.59928\n",
      "Epoch 21/300\n",
      "83/83 - 15s - loss: 0.5839 - accuracy: 0.3417 - val_loss: 0.6117 - val_accuracy: 0.2603\n",
      "\n",
      "Epoch 00021: val_loss did not improve from 0.59928\n",
      "Epoch 22/300\n",
      "83/83 - 15s - loss: 0.5833 - accuracy: 0.3607 - val_loss: 0.6171 - val_accuracy: 0.2466\n",
      "\n",
      "Epoch 00022: val_loss did not improve from 0.59928\n",
      "Epoch 23/300\n",
      "83/83 - 15s - loss: 0.5852 - accuracy: 0.3417 - val_loss: 0.6081 - val_accuracy: 0.3059\n",
      "\n",
      "Epoch 00023: val_loss did not improve from 0.59928\n",
      "Epoch 24/300\n",
      "83/83 - 15s - loss: 0.5819 - accuracy: 0.3546 - val_loss: 0.6069 - val_accuracy: 0.2785\n",
      "\n",
      "Epoch 00024: val_loss did not improve from 0.59928\n",
      "Epoch 25/300\n",
      "83/83 - 15s - loss: 0.5831 - accuracy: 0.3516 - val_loss: 0.6104 - val_accuracy: 0.2740\n",
      "\n",
      "Epoch 00025: val_loss did not improve from 0.59928\n",
      "Epoch 26/300\n",
      "83/83 - 15s - loss: 0.5853 - accuracy: 0.3394 - val_loss: 0.6031 - val_accuracy: 0.2877\n",
      "\n",
      "Epoch 00026: val_loss did not improve from 0.59928\n",
      "Epoch 27/300\n",
      "83/83 - 15s - loss: 0.5825 - accuracy: 0.3645 - val_loss: 0.6147 - val_accuracy: 0.2877\n",
      "\n",
      "Epoch 00027: val_loss did not improve from 0.59928\n",
      "Epoch 28/300\n",
      "83/83 - 15s - loss: 0.5832 - accuracy: 0.3485 - val_loss: 0.6049 - val_accuracy: 0.2420\n",
      "\n",
      "Epoch 00028: val_loss did not improve from 0.59928\n",
      "Epoch 29/300\n",
      "83/83 - 15s - loss: 0.5818 - accuracy: 0.3531 - val_loss: 0.6111 - val_accuracy: 0.2420\n",
      "\n",
      "Epoch 00029: val_loss did not improve from 0.59928\n",
      "Epoch 30/300\n",
      "83/83 - 15s - loss: 0.5820 - accuracy: 0.3637 - val_loss: 0.6157 - val_accuracy: 0.2420\n",
      "\n",
      "Epoch 00030: val_loss did not improve from 0.59928\n",
      "Epoch 31/300\n",
      "83/83 - 15s - loss: 0.5805 - accuracy: 0.3629 - val_loss: 0.6097 - val_accuracy: 0.2785\n",
      "\n",
      "Epoch 00031: val_loss did not improve from 0.59928\n",
      "Epoch 32/300\n",
      "83/83 - 15s - loss: 0.5786 - accuracy: 0.3546 - val_loss: 0.6150 - val_accuracy: 0.2329\n",
      "\n",
      "Epoch 00032: val_loss did not improve from 0.59928\n",
      "Epoch 33/300\n",
      "83/83 - 15s - loss: 0.5779 - accuracy: 0.3538 - val_loss: 0.6144 - val_accuracy: 0.3014\n",
      "\n",
      "Epoch 00033: val_loss did not improve from 0.59928\n",
      "Epoch 34/300\n",
      "83/83 - 15s - loss: 0.5800 - accuracy: 0.3645 - val_loss: 0.6150 - val_accuracy: 0.2420\n",
      "\n",
      "Epoch 00034: val_loss did not improve from 0.59928\n",
      "Epoch 35/300\n",
      "83/83 - 15s - loss: 0.5770 - accuracy: 0.3629 - val_loss: 0.6143 - val_accuracy: 0.3014\n",
      "\n",
      "Epoch 00035: val_loss did not improve from 0.59928\n",
      "Epoch 36/300\n",
      "83/83 - 15s - loss: 0.5796 - accuracy: 0.3652 - val_loss: 0.6124 - val_accuracy: 0.2694\n",
      "\n",
      "Epoch 00036: val_loss did not improve from 0.59928\n",
      "Epoch 37/300\n",
      "83/83 - 15s - loss: 0.5781 - accuracy: 0.3713 - val_loss: 0.6165 - val_accuracy: 0.2466\n",
      "\n",
      "Epoch 00037: val_loss did not improve from 0.59928\n",
      "Epoch 38/300\n",
      "83/83 - 15s - loss: 0.5767 - accuracy: 0.3721 - val_loss: 0.6114 - val_accuracy: 0.2557\n",
      "\n",
      "Epoch 00038: val_loss did not improve from 0.59928\n",
      "Epoch 39/300\n",
      "83/83 - 15s - loss: 0.5758 - accuracy: 0.3910 - val_loss: 0.6039 - val_accuracy: 0.3470\n",
      "\n",
      "Epoch 00039: val_loss did not improve from 0.59928\n",
      "Epoch 40/300\n",
      "83/83 - 15s - loss: 0.5768 - accuracy: 0.3804 - val_loss: 0.6208 - val_accuracy: 0.2466\n",
      "\n",
      "Epoch 00040: val_loss did not improve from 0.59928\n",
      "Epoch 41/300\n",
      "83/83 - 15s - loss: 0.5777 - accuracy: 0.3895 - val_loss: 0.6148 - val_accuracy: 0.2785\n",
      "\n",
      "Epoch 00041: val_loss did not improve from 0.59928\n",
      "Epoch 42/300\n",
      "83/83 - 15s - loss: 0.5772 - accuracy: 0.3759 - val_loss: 0.6102 - val_accuracy: 0.2694\n",
      "\n",
      "Epoch 00042: val_loss did not improve from 0.59928\n",
      "Epoch 43/300\n",
      "83/83 - 15s - loss: 0.5757 - accuracy: 0.3743 - val_loss: 0.6168 - val_accuracy: 0.2329\n",
      "\n",
      "Epoch 00043: val_loss did not improve from 0.59928\n",
      "Epoch 44/300\n",
      "83/83 - 15s - loss: 0.5766 - accuracy: 0.3789 - val_loss: 0.6224 - val_accuracy: 0.2694\n",
      "\n",
      "Epoch 00044: val_loss did not improve from 0.59928\n",
      "Epoch 45/300\n",
      "83/83 - 15s - loss: 0.5755 - accuracy: 0.3819 - val_loss: 0.6157 - val_accuracy: 0.2557\n",
      "\n",
      "Epoch 00045: val_loss did not improve from 0.59928\n",
      "Epoch 46/300\n",
      "83/83 - 16s - loss: 0.5706 - accuracy: 0.4002 - val_loss: 0.6115 - val_accuracy: 0.2648\n",
      "\n",
      "Epoch 00046: val_loss did not improve from 0.59928\n",
      "Epoch 47/300\n",
      "83/83 - 16s - loss: 0.5776 - accuracy: 0.3675 - val_loss: 0.6140 - val_accuracy: 0.2740\n",
      "\n",
      "Epoch 00047: val_loss did not improve from 0.59928\n",
      "Epoch 48/300\n",
      "83/83 - 15s - loss: 0.5753 - accuracy: 0.3926 - val_loss: 0.6183 - val_accuracy: 0.2603\n",
      "\n",
      "Epoch 00048: val_loss did not improve from 0.59928\n",
      "Epoch 49/300\n",
      "83/83 - 16s - loss: 0.5757 - accuracy: 0.3743 - val_loss: 0.6125 - val_accuracy: 0.2420\n",
      "\n",
      "Epoch 00049: val_loss did not improve from 0.59928\n",
      "Epoch 50/300\n",
      "83/83 - 15s - loss: 0.5744 - accuracy: 0.3834 - val_loss: 0.6102 - val_accuracy: 0.2237\n",
      "\n",
      "Epoch 00050: val_loss did not improve from 0.59928\n",
      "Epoch 51/300\n",
      "83/83 - 16s - loss: 0.5734 - accuracy: 0.3834 - val_loss: 0.6049 - val_accuracy: 0.2877\n",
      "\n",
      "Epoch 00051: val_loss did not improve from 0.59928\n",
      "Epoch 52/300\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-9-40e9d2553123>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     15\u001b[0m \u001b[0;31m# Riemannian geometry classification (below)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     16\u001b[0m \u001b[0;31m################################################################################\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 17\u001b[0;31m fittedModel = model.fit(X_train, Y_train, batch_size = 16, epochs = 300, \n\u001b[0m\u001b[1;32m     18\u001b[0m                         \u001b[0mverbose\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalidation_data\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_validate\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mY_validate\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     19\u001b[0m                         callbacks=[checkpointer])\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.8/site-packages/keras/engine/training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[1;32m   1182\u001b[0m                 _r=1):\n\u001b[1;32m   1183\u001b[0m               \u001b[0mcallbacks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_train_batch_begin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1184\u001b[0;31m               \u001b[0mtmp_logs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1185\u001b[0m               \u001b[0;32mif\u001b[0m \u001b[0mdata_handler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshould_sync\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1186\u001b[0m                 \u001b[0mcontext\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0masync_wait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.8/site-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    883\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    884\u001b[0m       \u001b[0;32mwith\u001b[0m \u001b[0mOptionalXlaContext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_jit_compile\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 885\u001b[0;31m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    886\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    887\u001b[0m       \u001b[0mnew_tracing_count\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexperimental_get_tracing_count\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.8/site-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36m_call\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    915\u001b[0m       \u001b[0;31m# In this case we have created variables on the first call, so we run the\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    916\u001b[0m       \u001b[0;31m# defunned version which is guaranteed to never create variables.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 917\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_stateless_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# pylint: disable=not-callable\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    918\u001b[0m     \u001b[0;32melif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_stateful_fn\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    919\u001b[0m       \u001b[0;31m# Release the lock early so that multiple threads can perform the call\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.8/site-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   3037\u001b[0m       (graph_function,\n\u001b[1;32m   3038\u001b[0m        filtered_flat_args) = self._maybe_define_function(args, kwargs)\n\u001b[0;32m-> 3039\u001b[0;31m     return graph_function._call_flat(\n\u001b[0m\u001b[1;32m   3040\u001b[0m         filtered_flat_args, captured_inputs=graph_function.captured_inputs)  # pylint: disable=protected-access\n\u001b[1;32m   3041\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.8/site-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m_call_flat\u001b[0;34m(self, args, captured_inputs, cancellation_manager)\u001b[0m\n\u001b[1;32m   1961\u001b[0m         and executing_eagerly):\n\u001b[1;32m   1962\u001b[0m       \u001b[0;31m# No tape is watching; skip to running the function.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1963\u001b[0;31m       return self._build_call_outputs(self._inference_function.call(\n\u001b[0m\u001b[1;32m   1964\u001b[0m           ctx, args, cancellation_manager=cancellation_manager))\n\u001b[1;32m   1965\u001b[0m     forward_backward = self._select_forward_and_backward_functions(\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.8/site-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36mcall\u001b[0;34m(self, ctx, args, cancellation_manager)\u001b[0m\n\u001b[1;32m    589\u001b[0m       \u001b[0;32mwith\u001b[0m \u001b[0m_InterpolateFunctionError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    590\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mcancellation_manager\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 591\u001b[0;31m           outputs = execute.execute(\n\u001b[0m\u001b[1;32m    592\u001b[0m               \u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msignature\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    593\u001b[0m               \u001b[0mnum_outputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_num_outputs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.8/site-packages/tensorflow/python/eager/execute.py\u001b[0m in \u001b[0;36mquick_execute\u001b[0;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[1;32m     57\u001b[0m   \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     58\u001b[0m     \u001b[0mctx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mensure_initialized\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 59\u001b[0;31m     tensors = pywrap_tfe.TFE_Py_Execute(ctx._handle, device_name, op_name,\n\u001b[0m\u001b[1;32m     60\u001b[0m                                         inputs, attrs, num_outputs)\n\u001b[1;32m     61\u001b[0m   \u001b[0;32mexcept\u001b[0m \u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_NotOkStatusException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "###############################################################################\n",
    "# if the classification task was imbalanced (significantly more trials in one\n",
    "# class versus the others) you can assign a weight to each class during \n",
    "# optimization to balance it out. This data is approximately balanced so we \n",
    "# don't need to do this, but is shown here for illustration/completeness. \n",
    "###############################################################################\n",
    "\n",
    "# the syntax is {class_1:weight_1, class_2:weight_2,...}. Here just setting\n",
    "# the weights all to be 1\n",
    "class_weights = {0:1, 1:1, 2:1, 3:1}\n",
    "\n",
    "################################################################################\n",
    "# fit the model. Due to very small sample sizes this can get\n",
    "# pretty noisy run-to-run, but most runs should be comparable to xDAWN + \n",
    "# Riemannian geometry classification (below)\n",
    "################################################################################\n",
    "fittedModel = model.fit(X_train, Y_train, batch_size = 16, epochs = 300, \n",
    "                        verbose = 2, validation_data=(X_validate, Y_validate),\n",
    "                        callbacks=[checkpointer])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a262fd58-fee7-4d1b-927b-85cf93492e49",
   "metadata": {},
   "outputs": [],
   "source": [
    "###############################################################################\n",
    "# make prediction on test set.\n",
    "###############################################################################\n",
    "\n",
    "probs       = model.predict(X_test)\n",
    "preds       = probs.argmax(axis = -1)  \n",
    "acc         = np.mean(preds == Y_test.argmax(axis=-1))\n",
    "print(\"Classification accuracy: %f \" % (acc))\n",
    "\n",
    "from sklearn.metrics import confusion_matrix, ConfusionMatrixDisplay\n",
    "cm = confusion_matrix(Y_test.argmax(axis=-1), preds)\n",
    "disp = ConfusionMatrixDisplay(confusion_matrix=cm)\n",
    "disp.plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e1bcd182-c2c1-4f9a-bbea-776b46be26dd",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "31f6a130-6c43-4d97-81aa-ac3852342dfd",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ca8584b-e554-4eb6-bb6e-40b84e194f1d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef21c5a2-2c10-4126-b33d-845de15c4280",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a7d42f3e-c04e-44e2-8f3f-b0b5c33f0625",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a126170e-8b7e-44bf-8370-031e4322f1de",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "91349487-e0fa-4247-b199-34f8f6f78238",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a0a78bb-35e2-444c-954d-08c622217f8f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
